---
title: "IMDB_Sentiment"
author: "Jonathan Yu"
date: "2/1/2022"
output: html_document
---

```{r}
library(tidyverse)
library(tm)
library(topicmodels)
library(SnowballC)
library(ggwordcloud)
library(RColorBrewer)
library(syuzhet)
library(lexicon)
library(tidytext)
library(textdata)
library(xgboost)
library(caret)
```
# Reading Data 
```{r}
akas <- read.table(file = "/Users/jonathanyu/Desktop/IMDBProject/title.akas.tsv", sep = '\t', header = TRUE, fill = TRUE)
akas <- subset(akas, region == "US")
akas <- subset(akas, ordering == 1)
akas$title <- tolower(akas$title)
akas$title <- gsub(" ", "-", akas$title)
titlebasics <- read.table(file = '/Users/jonathanyu/Desktop/IMDBProject/title.basics.tsv', sep = '\t', header = TRUE, fill = TRUE)
akastbmerge <- merge(akas, titlebasics, by.x = "titleId", by.y = "tconst")
                      
akastbmerge <-subset(akastbmerge, titleType == "movie")
akastbmerge

crew <- read.table(file = '/Users/jonathanyu/Desktop/IMDBProject/title.crew.tsv', sep = '\t', header = TRUE, fill = TRUE)
ratings <- read.table(file = '/Users/jonathanyu/Desktop/IMDBProject/title.ratings.tsv', sep = '\t', header = TRUE, fill = TRUE)

# Not Needed
episode <- read.table(file = '/Users/jonathanyu/Desktop/IMDBProject/title.episode.tsv', sep = '\t', header = TRUE, fill = TRUE)
principals <- read.table(file = '/Users/jonathanyu/Desktop/IMDBProject/title.principals.tsv', sep = '\t', header = TRUE, fill = TRUE)
namebasics <- read.table(file = "/Users/jonathanyu/Desktop/IMDBProject/name.basics.tsv", sep = '\t', header = TRUE, fill = TRUE)



```
# Read in txt files from folder
```{r}
scripts <- c(list.files(path = "/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/scripts"))
scriptslist <- as.list(scripts)
scripts <- as.data.frame(scripts)
scripts$scripts
scripts$scripts <- gsub(".txt", "", scripts$scripts)
#scriptsmerged <- merge(scripts, akastbmerge, by.x = "scripts", by.y = "title")
```

# Creation of Script Objects
```{r}
textscriptlist <- list()
g <- 0
for(script in scriptslist){
  assign(paste0("text", script), readLines(paste("/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/scripts/",script, sep = "")))
  g <- readLines(paste("/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/scripts/",script, sep = ""))
  textscriptlist[[length(textscriptlist)+1]] <- g
}
corpusscriptlist <- list()
for(script in textscriptlist){
  assign(paste0("corpus", script), Corpus(VectorSource(script)))
  g <- Corpus(VectorSource(script))
  corpusscriptlist[[length(corpusscriptlist)+1]] <- g            
}
removeExtras <- function(corpus){
  toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
  corpus <- tm_map(corpus, toSpace, "/")
  corpus <- tm_map(corpus, toSpace, "@")
  corpus <- tm_map(corpus, toSpace, "\\|")
  # Convert the text to lower case
  corpus <- tm_map(corpus, content_transformer(tolower))
  # Remove numbers
  corpus <- tm_map(corpus, removeNumbers)
  # Remove english common stopwords
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  # Remove your own stop word
  corpus <- tm_map(corpus, removeWords, c("continued", "contd", "int"))
  # Remove punctuations
  corpus <- tm_map(corpus, removePunctuation)
  # Eliminate extra white spaces
  corpus <- tm_map(corpus, stripWhitespace)
  # Text stemming - which reduces words to their root form
  # corpus <- tm_map(corpus, stemDocument)
  corpus  
}

finalscriptlist <- list()
for(script in corpusscriptlist){
  g <- removeExtras(script)
  finalscriptlist[[length(finalscriptlist)+1]] <- g
}
```

```{r}
# Build a term-document matrix
tdmlist <- list()
for(textdoc in finalscriptlist){
  dtm <- TermDocumentMatrix(textdoc)
  dtm_m <- as.matrix(dtm)
  dtm_v <- sort(rowSums(dtm_m), decreasing = TRUE)
  dtm_d <- data.frame(word = names(dtm_v), freq = dtm_v)
  tdmlist[[length(tdmlist)+1]] <- dtm_d
}

```

# Generate Wordcloud
```{r}
#generate word cloud
set.seed(1234)
wordcloudlist <- list()
for(tdm in tdmlist){
  wordcloudlist[[length(wordcloudlist)+1]] <- ggwordcloud(words = tdm$word, freq = tdm$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
}

wordcloudlist[3]
```

# Sentiment Analysis
```{r}
nrclist <- list()
counter <- 0
for(tdm in tdmlist){
  counter <- counter + 1
  print(counter)
  dftdm <- as.data.frame(tdm)
  sentimentdm <- get_nrc_sentiment(dftdm$word)
  sentimentdm <- as.data.frame(colSums(sentimentdm))
  nrclist[[length(nrclist)+1]] <- sentimentdm
}

```

# NRC dataframe with all 240 scripts
```{r}
nrcdf <- data.frame(matrix(ncol = 10, nrow = 0))
for(nrc in nrclist){
  temp <- as.data.frame(t(nrc))
  nrcdf <- rbind(nrcdf, temp)
}
rownames(nrcdf) <- scripts$scripts
nrcdf
nrcdf$name <- rownames(nrcdf)
write.csv(nrcdf, "nrcdf.csv")
```

# NRC ratings creation with 189 of the scripts
```{r}
ratings <- read.csv("scriptBasicRating.csv")
ratings <- select(ratings, c("primaryTitle", "averageRating"))
nrcratings <- merge(nrcdf, ratings, by.x = "name", by.y = "primaryTitle")
write.csv(nrcratings, "nrcratings.csv")
```

# XG Boost Model
```{r}
trainIndex <- createDataPartition(nrcratings$averageRating, p = 0.8, list = FALSE, times = 1)
head(trainIndex)
nrctrain <- nrcratings[trainIndex,]
nrctest <- nrcratings[-trainIndex,]
nrctest
nrcSparse <- xgboost(data = as.matrix(nrctrain[,2:11]), label = nrctrain$averageRating, max.depth = 2, eta = 0.3, nthread = 2, nrounds = 12, objective = "reg:squarederror")

pred <- predict(nrcSparse, as.matrix(nrctest[,2:11]))
print(head(pred))
predf <- as.data.frame(pred)
predf$real <- nrctest$averageRating
predf$error <- abs(predf$real - predf$pred)
predf
modelanalysis <- data.frame(ncol = 3, nrows = 0)
modelanalysis$mse <- mean((predf$real-predf$pred)^2)
modelanalysis$mse
modelanalysis$mae <- MAE(predf$real, predf$pred)
modelanalysis$RMSE <- caret::RMSE(predf$real, predf$pred)

plotlist <- list()
predf$real
predpred <- as.data.frame(predf$pred)
predpred$ID <- "prediction"
colnames(predpred)[1] <- "Value"
predreal <- as.data.frame(predf$real)
predreal$ID <- "real"
colnames(predreal)[1] <- "Value"
mergepredreal <- (rbind(predpred, predreal))
mergepredreal
```

# Generation of Graphs Comparing Regression Line and Real Values 
```{r}
plotlist <- list()
counter <- 0
names <- colnames(nrctest[,2:11])
for(column in nrctest[,2:11]){
  counter <- counter+1
  p <- ggplot(nrctest, aes(column, predf$pred)) + geom_point()
  p <- p + labs(x = names[counter], y = "Predicted Value")
  plotlist[[length(plotlist)+1]] <-  p 

}
plotlist[1]
range(nrcratings$averageRating)
```

