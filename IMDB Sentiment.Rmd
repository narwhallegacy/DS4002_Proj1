---
title: "IMDB_Sentiment"
author: "Jonathan Yu"
date: "2/1/2022"
output: html_document
---

```{r}
library(tidyverse)
library(tm)
library(topicmodels)
library(SnowballC)
library(ggwordcloud)
library(RColorBrewer)
library(syuzhet)
library(lexicon)
library(tidytext)
library(textdata)
library(xgboost)
library(parallel)
library(caret)
```

# Read in txt files from folder
```{r}
scripts <- c(list.files(path = "/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/imsdbscripts"))
scripts
scriptslist <- as.list(scripts)
scripts <- as.data.frame(scripts)
scripts$scripts
scripts$scripts <- gsub(".txt", "", scripts$scripts)
#scriptsmerged <- merge(scripts, akastbmerge, by.x = "scripts", by.y = "title")
```

# Creation of Script Objects
```{r}
textscriptlist <- list()
g <- 0
for(script in scriptslist){
  assign(paste0("text", script), readLines(paste("/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/imsdbscripts/",script, sep = "")))
  g <- readLines(paste("/Users/jonathanyu/Documents/GitHub/DS4002_Proj1/imsdbscripts/",script, sep = ""))
  textscriptlist[[length(textscriptlist)+1]] <- g
}
corpusscriptlist <- list()
for(script in textscriptlist){
  assign(paste0("corpus", script), Corpus(VectorSource(script)))
  g <- Corpus(VectorSource(script))
  corpusscriptlist[[length(corpusscriptlist)+1]] <- g            
}
removeExtras <- function(corpus){
  toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
  corpus <- tm_map(corpus, toSpace, "/")
  corpus <- tm_map(corpus, toSpace, "@")
  corpus <- tm_map(corpus, toSpace, "\\|")
  # Convert the text to lower case
  corpus <- tm_map(corpus, content_transformer(tolower))
  # Remove numbers
  corpus <- tm_map(corpus, removeNumbers)
  # Remove english common stopwords
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  # Remove your own stop word
  corpus <- tm_map(corpus, removeWords, c("continued", "contd", "int"))
  # Remove punctuations
  corpus <- tm_map(corpus, removePunctuation)
  # Eliminate extra white spaces
  corpus <- tm_map(corpus, stripWhitespace)
  # Text stemming - which reduces words to their root form
  # corpus <- tm_map(corpus, stemDocument)
  corpus  
}

finalscriptlist <- list()
for(script in corpusscriptlist){
  g <- removeExtras(script)
  finalscriptlist[[length(finalscriptlist)+1]] <- g
}
```

```{r}
# Build a term-document matrix
tdmlist <- list()
for(textdoc in finalscriptlist){
  dtm <- TermDocumentMatrix(textdoc)
  dtm_m <- as.matrix(dtm)
  dtm_v <- sort(rowSums(dtm_m), decreasing = TRUE)
  dtm_d <- data.frame(word = names(dtm_v), freq = dtm_v)
  tdmlist[[length(tdmlist)+1]] <- dtm_d
}

```

# Generate Wordcloud
```{r}
#generate word cloud
set.seed(1234)
wordcloudlist <- list()
for(tdm in tdmlist){
  wordcloudlist[[length(wordcloudlist)+1]] <- ggwordcloud(words = tdm$word, freq = tdm$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
}
for(word in wordcloudlist[1:10]){
  plot(word)
}

```

# Sentiment Analysis
```{r}
# Ones that don't work: 772, 362, 695, 820, 853
nrclist <- list()
counter <- 0
cl <- makeCluster(2)
clusterExport(cl = cl, c("get_sentiment", "get_sent_values", "get_nrc_sentiment", "get_nrc_values", "parLapply"))
for(tdm in tdmlist[362:1146]){
  counter <- counter + 1
  print(counter)
  if(length(tdm$word) <= 0){
    print(paste(counter, " does not work"))
  }
  else{
    dftdm <- as.data.frame(tdm)
    sentimentdm <- get_nrc_sentiment(dftdm$word)
    sentimentdm <- as.data.frame(colSums(sentimentdm))
    nrclist[[length(nrclist)+1]] <- sentimentdm
  }
  
}

```

# NRC dataframe with all 1045 scripts
```{r}
nrcdf <- data.frame(matrix(ncol = 10, nrow = 0))
for(nrc in nrclist){
  temp <- as.data.frame(t(nrc))
  nrcdf <- rbind(nrcdf, temp)
  
}
scripts$scripts
nrcdf <- nrcdf[-c(1),]
length(rownames(nrcdf))
rownames(nrcdf) <- scripts$scripts[-c(362, 772, 695, 820, 853)]
nrcdf$name <- rownames(nrcdf)
write.csv(nrcdf, "nrcdf1146.csv")
```

# NRC ratings creation with 1140 of the scripts
```{r}
ratings <- read.csv("AllBigMovies.csv")
linktable <- read.csv("linkTable.csv")
nrcdf$name <- paste(nrcdf$name, ".txt", sep = "")
ratings <- select(ratings, c("primaryTitle", "averageRating", "tconst"))
initiallink <- merge(nrcdf, linktable, by.x = "name", by.y = "file")
nrcratings <- merge(initiallink, ratings, by.x = "tconst", by.y = "tconst")
nrcratings <- subset(nrcratings, nrcratings$anger >= 5)
write.csv(nrcratings, "nrcratings.csv")
```

```{r}
sentimentdist <- colSums(nrcratings[,3:12])
sentimentdist <- as.data.frame(sentimentdist)
sentimentdist$sentiment <- rownames(sentimentdist)
sentimentdist
p <- ggplot(sentimentdist, aes(x = sentimentdist, y = sentiment, fill = sentiment)) + 
  geom_bar(stat = "identity") + theme_minimal() + scale_fill_brewer(palette = "Set3") + labs(x = "Number of Words", y = "Sentiment", title = "All Scripts (755)")
p
ratingdist <- nrcratings$averageRating
ratingdist <- as.data.frame(ratingdist)
histp <- ggplot(ratingdist, aes(x = ratingdist)) + geom_histogram(fill = "white", color = "black") + labs(x = "Average Rating", y = "Number of Movies", title = "Average Rating Distribution of All Scripts (755)")
histp
``` 

# Creation of Training and Test Sets and Visualizations 
```{r}
trainIndex <- createDataPartition(nrcratings$averageRating, p = 0.8, list = FALSE, times = 1)
head(trainIndex)
nrctrain <- nrcratings[trainIndex,]
nrctest <- nrcratings[-trainIndex,]
sentimentdisttrain <- colSums(nrctrain[,3:12])
sentimentdisttrain <- as.data.frame(sentimentdisttrain)
sentimentdisttrain$name <- rownames(sentimentdisttrain)
trainp <- ggplot(sentimentdisttrain, aes(x = sentimentdisttrain, y = name, fill = name)) + 
  geom_bar(stat = "identity") + theme_minimal() + scale_fill_brewer(palette = "Set3") + labs(x = "Number of Words", y = "Sentiment", title = "Training Scripts Distribution")
trainp
sentimentdisttest <- colSums(nrctest[,3:12])
sentimentdisttest <- as.data.frame(sentimentdisttest)
sentimentdisttest$name <- rownames(sentimentdisttest)
testp <- ggplot(sentimentdisttest, aes(x = sentimentdisttest, y = name, fill = name)) + 
  geom_bar(stat = "identity") + theme_minimal() + scale_fill_brewer(palette = "Set3") + labs(x = "Number of Words", y = "Sentiment", title = "Testing Scripts Distribution")
testp
```

# XG Boost Model 
```{r}
nrcSparse <- xgboost(data = as.matrix(nrctrain[,3:12]), label = nrctrain$averageRating, max.depth = 3, eta = 0.3, nthread = 2, nrounds = 13, objective = "reg:squarederror")

pred <- predict(nrcSparse, as.matrix(nrctest[,3:12]))
print(head(pred))
predf <- as.data.frame(pred)
predf$real <- nrctest$averageRating
predf$error <- abs(predf$real - predf$pred)
modelanalysis <- data.frame(row = 0)
modelanalysis$mse <- mean((predf$real-predf$pred)^2)
modelanalysis$mae <- MAE(predf$real, predf$pred)
modelanalysis$RMSE <- caret::RMSE(predf$real, predf$pred)
modelanalysis
saveRDS(nrcSparse, "xgboostsentiment.RDS")
readRDS("xgboostsentiment.RDS")
# rsq adjusted 

```




